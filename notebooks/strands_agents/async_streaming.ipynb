{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strands Agent Async Streaming\n",
    "\n",
    "Async streaming with iterators for real-time agent responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from strands import Agent\n",
    "from strands.models.openai import OpenAIModel\n",
    "from strands_tools import calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Local LLM Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIModel(\n",
    "    client_args={\n",
    "        \"api_key\": \"none\",\n",
    "        \"base_url\": \"http://localhost:1234/v1\",\n",
    "    },\n",
    "    model_id=\"local-model\",\n",
    "    params={\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.95,\n",
    "        \"frequency_penalty\": 0.0,\n",
    "        \"presence_penalty\": 0.0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=model,\n",
    "    tools=[calculator],\n",
    "    system_prompt=\"You are a calculator.\",\n",
    "    callback_handler=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Streaming Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_streaming_response():\n",
    "    prompt = \"Calculate 2 + 2\"\n",
    "    \n",
    "    agent_stream = agent.stream_async(prompt)\n",
    "    \n",
    "    async for event in agent_stream:\n",
    "        if \"data\" in event:\n",
    "            print(event[\"data\"], end=\"\", flush=True)\n",
    "        elif \"current_tool_use\" in event and event[\"current_tool_use\"].get(\"name\"):\n",
    "            print(f\"\\n[Tool use delta for: {event['current_tool_use']['name']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Streaming Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_streaming_response()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
